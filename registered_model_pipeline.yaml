# PIPELINE DEFINITION
# Name: enhanced-model-pipeline-with-metrics
components:
  comp-data-preprocessing:
    executorLabel: exec-data-preprocessing
    inputDefinitions:
      parameters:
        batch_size:
          parameterType: NUMBER_INTEGER
        max_features:
          parameterType: NUMBER_INTEGER
        random_state:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        processed_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        data_shape:
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        input_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        learning_rate:
          parameterType: NUMBER_DOUBLE
        n_estimators:
          parameterType: NUMBER_INTEGER
        max_depth:
          parameterType: NUMBER_INTEGER
        model_type:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        training_accuracy:
          parameterType: NUMBER_DOUBLE
        training_loss:
          parameterType: NUMBER_DOUBLE
        feature_importance:
          parameterType: STRING
  comp-evaluate-model:
    executorLabel: exec-evaluate-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        validation_split:
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      parameters:
        test_accuracy:
          parameterType: NUMBER_DOUBLE
        test_precision:
          parameterType: NUMBER_DOUBLE
        test_recall:
          parameterType: NUMBER_DOUBLE
        test_f1_score:
          parameterType: NUMBER_DOUBLE
        inference_time_ms:
          parameterType: NUMBER_DOUBLE
        model_size_mb:
          parameterType: NUMBER_DOUBLE
deploymentSpec:
  executors:
    exec-data-preprocessing:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ 'scikit-learn==1.3.0' 'pandas==2.0.3' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\n\
          \ndef preprocess_data(\n    batch_size: int,\n    max_features: int,\n    random_state: int,\n\
          \    processed_data: Output[Dataset],\n    data_shape: Output[str]\n):\n    \
          # Simulate data preprocessing\n    np.random.seed(random_state)\n    \
          # Generate synthetic dataset\n    n_samples = batch_size * 100\n    X = np.random.randn(n_samples, max_features)\n    \
          y = np.random.randint(0, 2, n_samples)\n    \n    # Apply standard scaling\n    \
          scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    \n    \
          # Create DataFrame and save\n    df = pd.DataFrame(X_scaled)\n    df['target'] = y\n    \
          df.to_csv(processed_data.path, index=False)\n    \n    # Output data shape as parameter\n    \
          data_shape.value = f'{n_samples}x{max_features}'\n    \n    # Add metadata\n    \
          processed_data.metadata['preprocessing'] = 'StandardScaler'\n    processed_data.metadata['features'] = str(max_features)\n\
          \    processed_data.metadata['samples'] = str(n_samples)\n\n"
        image: python:3.9
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ 'scikit-learn==1.3.0' 'pandas==2.0.3' 'joblib==1.3.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\n\
          from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\
          import joblib\nimport json\n\ndef train_model(\n    input_data: Input[Dataset],\n    \
          learning_rate: float,\n    n_estimators: int,\n    max_depth: int,\n    model_type: str,\n\
          \    output_model: Output[Artifact],\n    training_accuracy: Output[float],\n\
          \    training_loss: Output[float],\n    feature_importance: Output[str]\n):\n    \
          # Load preprocessed data\n    df = pd.read_csv(input_data.path)\n    X = df.drop('target', axis=1)\n    \
          y = df['target']\n    \n    # Split data\n    X_train, X_val, y_train, y_val = train_test_split(\n        \
          X, y, test_size=0.2, random_state=42\n    )\n    \n    # Train model based on type\n    \
          if model_type == 'random_forest':\n        model = RandomForestClassifier(\n            \
          n_estimators=n_estimators,\n            max_depth=max_depth,\n            random_state=42\n\
          \        )\n    else:  # logistic_regression\n        model = LogisticRegression(\n            \
          C=1.0/learning_rate,\n            max_iter=n_estimators,\n            random_state=42\n\
          \        )\n    \n    # Fit model\n    model.fit(X_train, y_train)\n    \n    # Calculate metrics\n    \
          train_acc = model.score(X_train, y_train)\n    val_acc = model.score(X_val, y_val)\n    \
          \n    # Simulate training loss (cross-entropy)\n    train_proba = model.predict_proba(X_train)\n    \
          loss = -np.mean(y_train * np.log(train_proba[:, 1] + 1e-15) + \n                   (1 - y_train) * np.log(train_proba[:, 0] + 1e-15))\n    \
          \n    # Feature importance\n    if hasattr(model, 'feature_importances_'):\n        \
          importance_dict = {f'feature_{i}': float(imp) for i, imp in enumerate(model.feature_importances_)}\n\
          \    else:\n        importance_dict = {f'feature_{i}': float(abs(coef)) for i, coef in enumerate(model.coef_[0])}\n    \
          \n    # Save model\n    joblib.dump(model, output_model.path)\n    \n    # Set output parameters\n    \
          training_accuracy.value = float(train_acc)\n    training_loss.value = float(loss)\n    \
          feature_importance.value = json.dumps(importance_dict)\n    \n    # Add model metadata\n    \
          output_model.metadata['modelType'] = model_type\n    output_model.metadata['registeredModelId'] = '49'\n\
          \    output_model.metadata['registeredModelName'] = f'Enhanced_{model_type}_Model'\n    \
          output_model.metadata['modelVersionId'] = '50'\n    output_model.metadata['modelVersionName'] = 'v1.0'\n\
          \    output_model.metadata['trainingAccuracy'] = str(train_acc)\n\n"
        image: python:3.9
    exec-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ 'scikit-learn==1.3.0' 'pandas==2.0.3' 'joblib==1.3.1' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\
          import joblib\nimport time\nimport os\n\ndef evaluate_model(\n    model: Input[Artifact],\n\
          \    test_data: Input[Dataset],\n    validation_split: float,\n    test_accuracy: Output[float],\n\
          \    test_precision: Output[float],\n    test_recall: Output[float],\n    test_f1_score: Output[float],\n\
          \    inference_time_ms: Output[float],\n    model_size_mb: Output[float]\n):\n    \
          # Load model and test data\n    trained_model = joblib.load(model.path)\n    df = pd.read_csv(test_data.path)\n    \
          X = df.drop('target', axis=1)\n    y = df['target']\n    \n    # Use validation split for testing\n    \
          test_size = int(len(X) * validation_split)\n    X_test = X.iloc[-test_size:]\n    y_test = y.iloc[-test_size:]\n    \
          \n    # Measure inference time\n    start_time = time.time()\n    y_pred = trained_model.predict(X_test)\n    \
          end_time = time.time()\n    \n    # Calculate metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    \
          precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n    \
          recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n    \
          f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n    \n    \
          # Calculate inference time and model size\n    inference_time = (end_time - start_time) * 1000 / len(X_test)  # ms per sample\n    \
          model_size = os.path.getsize(model.path) / (1024 * 1024)  # MB\n    \n    # Set output parameters\n    \
          test_accuracy.value = float(accuracy)\n    test_precision.value = float(precision)\n    \
          test_recall.value = float(recall)\n    test_f1_score.value = float(f1)\n    \
          inference_time_ms.value = float(inference_time)\n    model_size_mb.value = float(model_size)\n\n"
        image: python:3.9
pipelineInfo:
  name: enhanced-model-pipeline-with-metrics
root:
  dag:
    tasks:
      data-preprocessing:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-preprocessing
        inputs:
          parameters:
            batch_size:
              runtimeValue:
                constant: 64
            max_features:
              runtimeValue:
                constant: 20
            random_state:
              runtimeValue:
                constant: 42
        taskInfo:
          name: data-preprocessing
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - data-preprocessing
        inputs:
          artifacts:
            input_data:
              taskOutputArtifact:
                outputArtifactKey: processed_data
                producerTask: data-preprocessing
          parameters:
            learning_rate:
              runtimeValue:
                constant: 0.01
            n_estimators:
              runtimeValue:
                constant: 100
            max_depth:
              runtimeValue:
                constant: 10
            model_type:
              runtimeValue:
                constant: random_forest
        taskInfo:
          name: train-model
      evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model
        dependentTasks:
        - train-model
        - data-preprocessing
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: output_model
                producerTask: train-model
            test_data:
              taskOutputArtifact:
                outputArtifactKey: processed_data
                producerTask: data-preprocessing
          parameters:
            validation_split:
              runtimeValue:
                constant: 0.3
        taskInfo:
          name: evaluate-model
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0